import streamlit as st
import os
import json
import requests
from pathlib import Path
from PIL import Image
import io
import base64
from volcenginesdkarkruntime import Ark
from configparser import ConfigParser
from moviepy import VideoFileClip, concatenate_videoclips, AudioFileClip
import time
import asyncio
import websockets
import uuid
import json
import sys
import os

# æ·»åŠ protocolsæ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'æ–¹èˆŸAPI_è¯­éŸ³åˆæˆ'))
from protocols import MsgType, receive_message, full_client_request

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="é•¿è§†é¢‘ç”Ÿæˆåº”ç”¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# è¯»å–é…ç½®æ–‡ä»¶
config = ConfigParser()
config.read('æ–¹èˆŸæ¨¡å‹é…ç½®.cfg')

# åˆå§‹åŒ–æ–¹èˆŸå®¢æˆ·ç«¯
api_key = config.get('DEFAULT', 'api_key')
base_url = config.get('DEFAULT', 'base_url')
seedream_model_id = config.get('DEFAULT', 'seedream_model_id')
seedance_model_id = config.get('DEFAULT', 'seedance_model_id')
doubao_seed_model_id = config.get('DEFAULT', 'doubao_seed_model_id')

# è¯­éŸ³åˆæˆé…ç½®
tts_appid = config.get('DEFAULT', 'appid')
tts_access_token = config.get('DEFAULT', 'access_token')
tts_secret_key = config.get('DEFAULT', 'secret_key')
tts_voice_type = config.get('DEFAULT', 'voice_type')

client = Ark(base_url=base_url, api_key=api_key)

# æ–‡ä»¶è·¯å¾„é…ç½®
FILE_DIR = Path("æ–‡ä»¶ç”Ÿæˆ")
SCENE_INPUT_FILE = FILE_DIR / "ç”¨æˆ·è¾“å…¥åœºæ™¯.md"
STORYBOARD_FILE = FILE_DIR / "åˆ†é•œç”Ÿæˆç»“æœ.md"
EXTRACTION_FILE = FILE_DIR / "åˆ†é•œä¿¡æ¯æå–ç»“æœ.json"
VIDEO_DIR = FILE_DIR / "åˆ†é•œè§†é¢‘"
AUDIO_DIR = FILE_DIR / "åˆ†é•œéŸ³é¢‘"
AV_DIR = FILE_DIR / "éŸ³è§†é¢‘"

# ç¡®ä¿ç›®å½•å­˜åœ¨
FILE_DIR.mkdir(exist_ok=True)
VIDEO_DIR.mkdir(exist_ok=True)
AUDIO_DIR.mkdir(exist_ok=True)
AV_DIR.mkdir(exist_ok=True)

# è¯»å–Promptæ–‡ä»¶
def read_prompt_file(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return ""

STORYBOARD_PROMPT = read_prompt_file("åˆ†é•œç”ŸæˆPrompt.md")
EXTRACTION_PROMPT = read_prompt_file("åˆ†é•œä¿¡æ¯æå–Prompt.md")
IMAGE_PROMPT_TEMPLATE = read_prompt_file("åˆ†é•œå›¾ç‰‡ç”ŸæˆPrompt.md")
VIDEO_PROMPT_PROMPT = read_prompt_file("åˆ†é•œç”Ÿæˆè§†é¢‘Promptçš„Prompt.md")

# å·¥å…·å‡½æ•°
def save_file(content, filepath):
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

def read_file(filepath):
    if filepath.exists():
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    return ""

def call_doubao_seed_model(messages):
    try:
        completion = client.chat.completions.create(
            model=doubao_seed_model_id,
            messages=messages,
        )
        return completion.choices[0].message.content
    except Exception as e:
        st.error(f"è°ƒç”¨è±†åŒ…Seed1.6æ¨¡å‹å¤±è´¥: {e}")
        return ""

def generate_storyboard(user_input):
    prompt = STORYBOARD_PROMPT.replace("{USER_INPUT}", user_input)
    messages = [{"role": "user", "content": prompt}]
    result = call_doubao_seed_model(messages)
    if result:
        save_file(result, STORYBOARD_FILE)
    return result

def extract_storyboard_info(storyboard_content):
    prompt = EXTRACTION_PROMPT.replace("{{input}}", storyboard_content)
    messages = [{"role": "user", "content": prompt}]
    result = call_doubao_seed_model(messages)
    if result:
        try:
            json_data = json.loads(result)
            save_file(json.dumps(json_data, ensure_ascii=False, indent=2), EXTRACTION_FILE)
            return json_data
        except json.JSONDecodeError:
            st.error("åˆ†é•œä¿¡æ¯æå–ç»“æœä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            return None
    return None

def generate_scene_image(scene_description, index):
    prompt = IMAGE_PROMPT_TEMPLATE.replace("{åœºæ™¯}", scene_description)
    try:
        response = client.images.generate(
            model=seedream_model_id,
            prompt=prompt,
            size="1024x1024"
        )
        image_url = response.data[0].url
        img_response = requests.get(image_url)
        img = Image.open(io.BytesIO(img_response.content))
        image_path = FILE_DIR / f"åˆ†é•œå›¾ç‰‡_{index+1}.jpg"
        img.save(image_path)
        return img, image_path
    except Exception as e:
        st.error(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
        return None, None

def generate_video_prompt(scene_description, index):
    messages = [
        {"role": "system", "content": VIDEO_PROMPT_PROMPT},
        {"role": "user", "content": scene_description}
    ]
    result = call_doubao_seed_model(messages)
    if result:
        prompt_path = FILE_DIR / f"ç”Ÿæˆè§†é¢‘Prompt_{index+1}.md"
        save_file(result, prompt_path)
    return result

def generate_scene_video(video_prompt, image_path, index):
    try:
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        # ä½¿ç”¨content_generation.tasks.createè¿›è¡Œè§†é¢‘ç”Ÿæˆ
        create_result = client.content_generation.tasks.create(
            model=seedance_model_id,
            content=[
                {
                    "type": "text",
                    "text": video_prompt  # åªä½¿ç”¨è§†é¢‘æç¤ºè¯ï¼Œä¸æ·»åŠ å‚æ•°
                },
                {
                    "type": "image_url", 
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
            ]
        )
        
        task_id = create_result.id
        
        # è½®è¯¢ä»»åŠ¡çŠ¶æ€
        while True:
            get_result = client.content_generation.tasks.get(task_id=task_id)
            status = get_result.status
            if status == "succeeded":
                video_url = get_result.content.video_url
                break
            elif status == "failed":
                st.error(f"è§†é¢‘ç”Ÿæˆä»»åŠ¡å¤±è´¥: {get_result.error}")
                return None, None
            else:
                time.sleep(1)
        
        url_path = FILE_DIR / f"åˆ†é•œè§†é¢‘_{index+1}.txt"
        save_file(video_url, url_path)
        video_response = requests.get(video_url)
        video_path = VIDEO_DIR / f"åˆ†é•œè§†é¢‘_{index+1}.mp4"
        with open(video_path, 'wb') as f:
            f.write(video_response.content)
        return video_path, video_url
    except Exception as e:
        st.error(f"ç”Ÿæˆè§†é¢‘å¤±è´¥: {e}")
        return None, None

# è¯­éŸ³åˆæˆå‡½æ•°
async def generate_scene_audio(narration, index):
    """ç”Ÿæˆåœºæ™¯éŸ³é¢‘"""
    try:
        # WebSocketè¿æ¥é…ç½®
        endpoint = "wss://openspeech.bytedance.com/api/v1/tts/ws_binary"
        headers = {
            "Authorization": f"Bearer;{tts_access_token}",
        }
        
        # è¿æ¥WebSocket
        websocket = await websockets.connect(
            endpoint, additional_headers=headers, max_size=10 * 1024 * 1024
        )
        
        try:
            # å‡†å¤‡è¯·æ±‚è´Ÿè½½
            request = {
                "app": {
                    "appid": tts_appid,
                    "token": tts_access_token,
                    "cluster": "volcano_tts",
                },
                "user": {
                    "uid": str(uuid.uuid4()),
                },
                "audio": {
                    "voice_type": tts_voice_type,
                    "encoding": "wav",
                },
                "request": {
                    "reqid": str(uuid.uuid4()),
                    "text": narration,
                    "operation": "submit",
                    "with_timestamp": "1",
                    "extra_param": json.dumps({
                        "disable_markdown_filter": False,
                    }),
                },
            }
            
            # ä½¿ç”¨åè®®åº“å‘é€è¯·æ±‚
            await full_client_request(websocket, json.dumps(request).encode())
            
            # æ¥æ”¶éŸ³é¢‘æ•°æ®
            audio_data = bytearray()
            while True:
                msg = await receive_message(websocket)
                
                if msg.type == MsgType.FrontEndResultServer:
                    continue
                elif msg.type == MsgType.AudioOnlyServer:
                    audio_data.extend(msg.payload)
                    if msg.sequence < 0:  # Last message
                        break
                else:
                    st.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {msg}")
                    return None
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
            if audio_data:
                audio_path = AUDIO_DIR / f"åˆ†é•œéŸ³é¢‘_{index+1}.wav"
                with open(audio_path, 'wb') as f:
                    f.write(audio_data)
                
                # ä¿å­˜éŸ³é¢‘URLåˆ°æ–‡ä»¶
                url_path = FILE_DIR / f"åˆ†é•œéŸ³é¢‘_{index+1}.txt"
                save_file(str(audio_path), url_path)
                
                return audio_path
            else:
                st.error("æœªæ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®")
                return None
            
        finally:
            await websocket.close()
            
    except Exception as e:
        st.error(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
        return None

# éŸ³è§†é¢‘åˆæˆå‡½æ•°
def concatenate_audio_video(video_path, audio_path, index):
    """å°†è§†é¢‘å’ŒéŸ³é¢‘åˆæˆä¸ºæœ‰éŸ³é¢‘çš„è§†é¢‘"""
    try:
        video_clip = VideoFileClip(str(video_path))
        audio_clip = AudioFileClip(str(audio_path))
        
        # è®¾ç½®è§†é¢‘çš„éŸ³é¢‘ï¼ˆå…¼å®¹moviepy 2.0.0ï¼‰
        # åœ¨moviepy 2.0.0ä¸­ï¼Œset_audioæ–¹æ³•å¯èƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨audioå‚æ•°
        final_clip = video_clip.with_audio(audio_clip)
        
        # ä¿å­˜åˆæˆåçš„è§†é¢‘
        av_path = AV_DIR / f"éŸ³è§†é¢‘_{index+1}.mp4"
        final_clip.write_videofile(str(av_path), codec='libx264', audio_codec='aac')
        
        return av_path
        
    except Exception as e:
        st.error(f"éŸ³è§†é¢‘åˆæˆå¤±è´¥: {e}")
        return None

# è§†é¢‘æ‹¼æ¥å‡½æ•°
def concatenate_all_videos():
    """æ‹¼æ¥æ‰€æœ‰éŸ³è§†é¢‘ä¸ºä¸€ä¸ªé•¿è§†é¢‘"""
    try:
        av_files = sorted(AV_DIR.glob("éŸ³è§†é¢‘_*.mp4"))
        if not av_files:
            st.error("æ²¡æœ‰æ‰¾åˆ°éŸ³è§†é¢‘æ–‡ä»¶")
            return None
        
        clips = [VideoFileClip(str(av_file)) for av_file in av_files]
        final_clip = concatenate_videoclips(clips)
        
        final_path = FILE_DIR / "æ‹¼æ¥è§†é¢‘.mp4"
        final_clip.write_videofile(str(final_path), codec='libx264', audio_codec='aac')
        
        return final_path
        
    except Exception as e:
        st.error(f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {e}")
        return None

# ä¸»åº”ç”¨
def main():
    st.title("ğŸ¬ é•¿è§†é¢‘ç”Ÿæˆåº”ç”¨")
    
    # åˆå§‹åŒ–session state
    if 'storyboard_data' not in st.session_state:
        st.session_state.storyboard_data = None
    if 'extracted_data' not in st.session_state:
        st.session_state.extracted_data = None
    if 'scene_images' not in st.session_state:
        st.session_state.scene_images = {}
    if 'video_prompts' not in st.session_state:
        st.session_state.video_prompts = {}
    if 'scene_videos' not in st.session_state:
        st.session_state.scene_videos = {}
    if 'scene_audios' not in st.session_state:
        st.session_state.scene_audios = {}
    if 'scene_avs' not in st.session_state:
        st.session_state.scene_avs = {}
    
    # æ­¥éª¤ä¸€ï¼šåˆ†é•œç”Ÿæˆ
    st.header("æ­¥éª¤ä¸€ï¼šåˆ†é•œç”Ÿæˆ")
    existing_input = read_file(SCENE_INPUT_FILE)
    user_input = st.text_area("è¯·è¾“å…¥åœºæ™¯éœ€æ±‚ï¼š", value=existing_input, height=100)
    
    if st.button("åˆ†é•œç”Ÿæˆ", key="generate_storyboard"):
        if user_input:
            save_file(user_input, SCENE_INPUT_FILE)
            with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†é•œä¿¡æ¯..."):
                storyboard = generate_storyboard(user_input)
                if storyboard:
                    st.session_state.storyboard_data = storyboard
                    st.success("åˆ†é•œç”ŸæˆæˆåŠŸï¼")
                else:
                    st.error("åˆ†é•œç”Ÿæˆå¤±è´¥")
        else:
            st.warning("è¯·è¾“å…¥åœºæ™¯éœ€æ±‚")
    
    # æ¸…ç©ºæŒ‰é’®
    if st.button("æ¸…ç©ºæ‰€æœ‰æ•°æ®", key="clear_all_data"):
        st.session_state.storyboard_data = None
        st.session_state.extracted_data = None
        st.session_state.scene_images = {}
        st.session_state.video_prompts = {}
        st.session_state.scene_videos = {}
        st.session_state.scene_audios = {}
        st.session_state.scene_avs = {}
        
        # åˆ é™¤æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
        import shutil
        if FILE_DIR.exists():
            shutil.rmtree(FILE_DIR)
        FILE_DIR.mkdir(exist_ok=True)
        VIDEO_DIR.mkdir(exist_ok=True)
        AUDIO_DIR.mkdir(exist_ok=True)
        AV_DIR.mkdir(exist_ok=True)
        
        st.success("æ‰€æœ‰æ•°æ®å·²æ¸…ç©ºï¼å¯ä»¥å¼€å§‹æ–°çš„ä»»åŠ¡äº†ã€‚")
        st.rerun()
    
    # æ˜¾ç¤ºåˆ†é•œç”Ÿæˆç»“æœ
    existing_storyboard = read_file(STORYBOARD_FILE)
    if existing_storyboard:
        st.session_state.storyboard_data = existing_storyboard
    
    if st.session_state.storyboard_data:
        st.subheader("åˆ†é•œç”Ÿæˆç»“æœ")
        st.text_area("åˆ†é•œå†…å®¹", st.session_state.storyboard_data, height=300)
    
    # æ­¥éª¤äºŒï¼šåˆ†é•œä¿¡æ¯æå–
    if st.session_state.storyboard_data:
        st.header("æ­¥éª¤äºŒï¼šåˆ†é•œä¿¡æ¯æå–")
        if st.button("æå–åˆ†é•œä¿¡æ¯", key="extract_info"):
            with st.spinner("æ­£åœ¨æå–åˆ†é•œä¿¡æ¯..."):
                extracted_data = extract_storyboard_info(st.session_state.storyboard_data)
                if extracted_data:
                    st.session_state.extracted_data = extracted_data
                    st.success("åˆ†é•œä¿¡æ¯æå–æˆåŠŸï¼")
                else:
                    st.error("åˆ†é•œä¿¡æ¯æå–å¤±è´¥")
        
        existing_extraction = read_file(EXTRACTION_FILE)
        if existing_extraction:
            try:
                st.session_state.extracted_data = json.loads(existing_extraction)
            except json.JSONDecodeError:
                pass
        
        if st.session_state.extracted_data:
            st.subheader("æå–ç»“æœ")
            col1, col2 = st.columns(2)
            with col1:
                st.text_area("ç”»é£", st.session_state.extracted_data.get("ç”»é£", ""), height=100)
            with col2:
                st.text_area("è§’è‰²è®¾å®š", st.session_state.extracted_data.get("è§’è‰²è®¾å®š", ""), height=100)
            
            # åœºæ™¯åˆ—è¡¨
            st.subheader("åœºæ™¯åˆ—è¡¨")
            scene_list = st.session_state.extracted_data.get("åœºæ™¯åˆ—è¡¨", [])
            for i, scene in enumerate(scene_list):
                st.markdown(f"**åœºæ™¯ {i+1}**")
                col1, col2 = st.columns(2)
                with col1:
                    st.text_area(f"åœºæ™¯æè¿° {i+1}", scene.get("åœºæ™¯", ""), height=100, key=f"scene_{i}")
                with col2:
                    st.text_area(f"æ—ç™½ {i+1}", scene.get("æ—ç™½", ""), height=100, key=f"narration_{i}")
                
                # å›¾ç‰‡ç”Ÿæˆ
                if st.button(f"ç”Ÿæˆåˆ†é•œå›¾ç‰‡ {i+1}", key=f"generate_image_{i}"):
                    with st.spinner(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1} çš„å›¾ç‰‡..."):
                        img, img_path = generate_scene_image(scene.get("åœºæ™¯", ""), i)
                        if img:
                            st.session_state.scene_images[i] = img
                            st.success(f"åœºæ™¯ {i+1} å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error(f"åœºæ™¯ {i+1} å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
                
                image_path = FILE_DIR / f"åˆ†é•œå›¾ç‰‡_{i+1}.jpg"
                if image_path.exists():
                    st.image(str(image_path), caption=f"åœºæ™¯ {i+1} å›¾ç‰‡")
                
                # è§†é¢‘Promptç”Ÿæˆ
                if st.button(f"ç”Ÿæˆè§†é¢‘Prompt {i+1}", key=f"generate_video_prompt_{i}"):
                    with st.spinner(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1} çš„è§†é¢‘Prompt..."):
                        video_prompt = generate_video_prompt(scene.get("åœºæ™¯", ""), i)
                        if video_prompt:
                            st.session_state.video_prompts[i] = video_prompt
                            st.success(f"åœºæ™¯ {i+1} è§†é¢‘Promptç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error(f"åœºæ™¯ {i+1} è§†é¢‘Promptç”Ÿæˆå¤±è´¥")
                
                # æ˜¾ç¤ºè§†é¢‘Promptï¼ˆä¼˜å…ˆæ˜¾ç¤ºsession stateä¸­çš„ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„ï¼‰
                prompt_path = FILE_DIR / f"ç”Ÿæˆè§†é¢‘Prompt_{i+1}.md"
                if i in st.session_state.video_prompts:
                    st.text_area(f"è§†é¢‘Prompt {i+1}", st.session_state.video_prompts[i], height=100, key=f"video_prompt_{i}")
                elif prompt_path.exists():
                    video_prompt = read_file(prompt_path)
                    st.text_area(f"è§†é¢‘Prompt {i+1}", video_prompt, height=100, key=f"video_prompt_{i}")
                
                # éŸ³é¢‘ç”Ÿæˆ
                if st.button(f"ç”ŸæˆéŸ³é¢‘ {i+1}", key=f"generate_audio_{i}"):
                    narration = scene.get("æ—ç™½", "")
                    if narration:
                        with st.spinner(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1} çš„éŸ³é¢‘..."):
                            audio_path = asyncio.run(generate_scene_audio(narration, i))
                            if audio_path:
                                st.session_state.scene_audios[i] = audio_path
                                st.success(f"åœºæ™¯ {i+1} éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼")
                            else:
                                st.error(f"åœºæ™¯ {i+1} éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
                    else:
                        st.warning("è¯¥åœºæ™¯æ²¡æœ‰æ—ç™½å†…å®¹")
                
                # æ˜¾ç¤ºéŸ³é¢‘
                audio_path = AUDIO_DIR / f"åˆ†é•œéŸ³é¢‘_{i+1}.wav"
                if audio_path.exists():
                    st.audio(str(audio_path))
                
                # è§†é¢‘ç”Ÿæˆ
                if st.button(f"ç”Ÿæˆåˆ†é•œè§†é¢‘ {i+1}", key=f"generate_video_{i}"):
                    image_path = FILE_DIR / f"åˆ†é•œå›¾ç‰‡_{i+1}.jpg"
                    prompt_path = FILE_DIR / f"ç”Ÿæˆè§†é¢‘Prompt_{i+1}.md"
                    audio_path = AUDIO_DIR / f"åˆ†é•œéŸ³é¢‘_{i+1}.wav"
                    # è¾…åŠ©å‡½æ•°ï¼šè·å–è§†é¢‘æ—¶é•¿
                    def get_video_duration(video_path):
                        try:
                            clip = VideoFileClip(str(video_path))
                            duration = clip.duration
                            clip.close()
                            return duration
                        except Exception as e:
                            st.error(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {e}")
                            return None

                    # è¾…åŠ©å‡½æ•°ï¼šè·å–éŸ³é¢‘æ—¶é•¿
                    def get_audio_duration(audio_path):
                        try:
                            clip = AudioFileClip(str(audio_path))
                            duration = clip.duration
                            clip.close()
                            return duration
                        except Exception as e:
                            st.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
                            return None

                    # è¾…åŠ©å‡½æ•°ï¼šæˆªå–è§†é¢‘åˆ°æŒ‡å®šæ—¶é•¿
                    def trim_video_to_duration(video_path, target_duration, output_path):
                        try:
                            # ä½¿ç”¨ffmpegç›´æ¥æˆªå–è§†é¢‘ï¼Œè¿™æ˜¯æœ€å¯é çš„æ–¹æ³•
                            import subprocess
                            
                            # é¦–å…ˆè·å–è§†é¢‘çš„å®é™…æ—¶é•¿
                            clip = VideoFileClip(str(video_path))
                            actual_duration = clip.duration
                            clip.close()
                            
                            if actual_duration > target_duration:
                                # ä½¿ç”¨ffmpegæˆªå–è§†é¢‘
                                input_file = str(video_path)
                                output_file = str(output_path)
                                
                                # ä½¿ç”¨ffmpegçš„-tå‚æ•°æŒ‡å®šæŒç»­æ—¶é—´
                                result = subprocess.run([
                                    'ffmpeg', '-i', input_file, '-t', str(target_duration),
                                    '-c', 'copy', output_file, '-y'
                                ], capture_output=True, text=True)
                                
                                if result.returncode == 0:
                                    return output_path
                                else:
                                    st.error(f"ffmpegæˆªå–è§†é¢‘å¤±è´¥: {result.stderr}")
                                    return None
                            else:
                                # å¦‚æœè§†é¢‘æ—¶é•¿å·²ç»å°äºç­‰äºç›®æ ‡æ—¶é•¿ï¼Œç›´æ¥å¤åˆ¶æ–‡ä»¶
                                import shutil
                                shutil.copy2(video_path, output_path)
                            return output_path
                            
                        except Exception as e:
                            st.error(f"æˆªå–è§†é¢‘å¤±è´¥: {e}")
                        return None

                    # è¾…åŠ©å‡½æ•°ï¼šæˆªå–è§†é¢‘å°¾å¸§
                    def extract_last_frame(video_path, output_image_path):
                        try:
                            clip = VideoFileClip(str(video_path))
                            # è·å–è§†é¢‘çš„æœ€åä¸€å¸§ï¼ˆåœ¨ç»“æŸå‰0.1ç§’çš„ä½ç½®ï¼‰
                            last_frame_time = max(0, clip.duration - 0.1)
                            last_frame = clip.get_frame(last_frame_time)
                            clip.close()
                            
                            # ä¿å­˜å°¾å¸§ä¸ºå›¾ç‰‡
                            from PIL import Image
                            img = Image.fromarray(last_frame)
                            img.save(str(output_image_path))
                            return output_image_path
                        except Exception as e:
                            st.error(f"æˆªå–è§†é¢‘å°¾å¸§å¤±è´¥: {e}")
                            return None

                    # è¾…åŠ©å‡½æ•°ï¼šæ‹¼æ¥è§†é¢‘
                    def concatenate_videos(video_paths, output_path):
                        try:
                            clips = [VideoFileClip(str(path)) for path in video_paths]
                            final_clip = concatenate_videoclips(clips)
                            final_clip.write_videofile(str(output_path), codec='libx264', audio_codec='aac')
                            final_clip.close()
                            return output_path
                        except Exception as e:
                            st.error(f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {e}")
                            return None

                    # è¾…åŠ©å‡½æ•°ï¼šè°ƒæ•´è§†é¢‘æ’­æ”¾é€Ÿåº¦ä»¥åŒ¹é…éŸ³é¢‘æ—¶é•¿
                    def adjust_video_speed(video_path, target_duration, output_path):
                        try:
                            clip = VideoFileClip(str(video_path))
                            current_duration = clip.duration
                            
                            # è®¡ç®—éœ€è¦çš„é€Ÿåº¦è°ƒæ•´æ¯”ä¾‹
                            speed_factor = current_duration / target_duration
                            
                            # ä½¿ç”¨ffmpegå‘½ä»¤è¡Œå·¥å…·è°ƒæ•´è§†é¢‘é€Ÿåº¦ï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
                            import subprocess
                            
                            # ä½¿ç”¨ffmpegçš„atempoæ»¤é•œè°ƒæ•´é€Ÿåº¦
                            result = subprocess.run([
                                'ffmpeg', '-i', str(video_path),
                                '-filter:a', f'atempo={speed_factor}',
                                '-filter:v', f'setpts={1/speed_factor}*PTS',
                                str(output_path), '-y'
                            ], capture_output=True, text=True)
                            
                            clip.close()
                            
                            if result.returncode == 0:
                                return output_path
                            else:
                                st.error(f"ffmpegé€Ÿåº¦è°ƒæ•´å¤±è´¥: {result.stderr}")
                                return None
                        except Exception as e:
                            st.error(f"è°ƒæ•´è§†é¢‘é€Ÿåº¦å¤±è´¥: {e}")
                            return None

                    # ä¿®æ”¹è§†é¢‘ç”Ÿæˆå‡½æ•°æ¥å¤„ç†éŸ³è§†é¢‘æ—¶é•¿è°ƒæ•´ï¼ˆé€šè¿‡è°ƒæ•´æ’­æ”¾é€Ÿåº¦ï¼‰
                    def generate_scene_video_with_audio_adjustment(video_prompt, image_path, audio_path, index):
                        """ç”Ÿæˆåœºæ™¯è§†é¢‘å¹¶é€šè¿‡è°ƒæ•´æ’­æ”¾é€Ÿåº¦åŒ¹é…éŸ³é¢‘æ—¶é•¿"""
                        try:
                            # æ­¥éª¤1ï¼šå…ˆç”ŸæˆåŸå§‹è§†é¢‘
                            video_path, video_url = generate_scene_video(video_prompt, image_path, index)
                            if not video_path:
                                return None, None
                            
                            # è·å–éŸ³è§†é¢‘æ—¶é•¿
                            video_duration = get_video_duration(video_path)
                            audio_duration = get_audio_duration(audio_path)
                            
                            if video_duration is None or audio_duration is None:
                                return video_path, video_url
                            
                            # å¦‚æœè§†é¢‘æ—¶é•¿ä¸éŸ³é¢‘æ—¶é•¿ä¸€è‡´ï¼Œç›´æ¥è¿”å›
                            if abs(video_duration - audio_duration) < 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
                                return video_path, video_url
                            
                            # æ­¥éª¤2ï¼šè°ƒæ•´è§†é¢‘æ’­æ”¾é€Ÿåº¦ä»¥åŒ¹é…éŸ³é¢‘æ—¶é•¿
                            final_video_path = VIDEO_DIR / f"åˆ†é•œè§†é¢‘_{index+1}_adjusted.mp4"
                            result = adjust_video_speed(video_path, audio_duration, final_video_path)
                            
                            if result:
                                st.success(f"è§†é¢‘é€Ÿåº¦å·²è°ƒæ•´ï¼šåŸæ—¶é•¿ {video_duration:.2f}s â†’ æ–°æ—¶é•¿ {audio_duration:.2f}s")
                                return result, video_url
                            else:
                                st.error("è§†é¢‘é€Ÿåº¦è°ƒæ•´å¤±è´¥")
                                return video_path, video_url
                            
                        except Exception as e:
                            st.error(f"éŸ³è§†é¢‘æ—¶é•¿è°ƒæ•´å¤±è´¥: {e}")
                            return video_path, video_url
                    if image_path.exists() and prompt_path.exists() and audio_path.exists():
                        video_prompt = read_file(prompt_path)
                        with st.spinner(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1} çš„è§†é¢‘å¹¶è°ƒæ•´æ—¶é•¿..."):
                            video_path, video_url = generate_scene_video_with_audio_adjustment(video_prompt, image_path, audio_path, i)
                            if video_path:
                                st.session_state.scene_videos[i] = video_path
                                st.success(f"åœºæ™¯ {i+1} è§†é¢‘ç”ŸæˆæˆåŠŸï¼")
                            else:
                                st.error(f"åœºæ™¯ {i+1} è§†é¢‘ç”Ÿæˆå¤±è´¥")
                    else:
                        st.warning("è¯·å…ˆç”Ÿæˆå›¾ç‰‡ã€è§†é¢‘Promptå’ŒéŸ³é¢‘")
                
                # æ˜¾ç¤ºè§†é¢‘ï¼ˆä¼˜å…ˆæ˜¾ç¤ºsession stateä¸­çš„ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„ï¼‰
                video_path = VIDEO_DIR / f"åˆ†é•œè§†é¢‘_{i+1}.mp4"
                if i in st.session_state.scene_videos:
                    st.video(str(st.session_state.scene_videos[i]))
                elif video_path.exists():
                    st.video(str(video_path))
                
                # éŸ³è§†é¢‘åˆæˆ
                if st.button(f"éŸ³è§†é¢‘åˆæˆ {i+1}", key=f"concatenate_av_{i}"):
                    video_path = VIDEO_DIR / f"åˆ†é•œè§†é¢‘_{i+1}.mp4"
                    audio_path = AUDIO_DIR / f"åˆ†é•œéŸ³é¢‘_{i+1}.wav"
                    if video_path.exists() and audio_path.exists():
                        with st.spinner(f"æ­£åœ¨åˆæˆåœºæ™¯ {i+1} çš„éŸ³è§†é¢‘..."):
                            av_path = concatenate_audio_video(video_path, audio_path, i)
                            if av_path:
                                st.session_state.scene_avs[i] = av_path
                                st.success(f"åœºæ™¯ {i+1} éŸ³è§†é¢‘åˆæˆæˆåŠŸï¼")
                            else:
                                st.error(f"åœºæ™¯ {i+1} éŸ³è§†é¢‘åˆæˆå¤±è´¥")
                    else:
                        st.warning("è¯·å…ˆç”Ÿæˆè§†é¢‘å’ŒéŸ³é¢‘")
                
                # æ˜¾ç¤ºéŸ³è§†é¢‘
                av_path = AV_DIR / f"éŸ³è§†é¢‘_{i+1}.mp4"
                if av_path.exists():
                    st.video(str(av_path))
                
                st.divider()
    
    # æ­¥éª¤å…«ï¼šè§†é¢‘æ‹¼æ¥
    if st.session_state.extracted_data:
        st.header("æ­¥éª¤å…«ï¼šè§†é¢‘æ‹¼æ¥")
        if st.button("æ‹¼æ¥è§†é¢‘", key="concatenate_videos"):
            with st.spinner("æ­£åœ¨æ‹¼æ¥æ‰€æœ‰è§†é¢‘..."):
                final_video_path = concatenate_all_videos()
                if final_video_path:
                    st.success("è§†é¢‘æ‹¼æ¥æˆåŠŸï¼")
                    st.video(str(final_video_path))
                    with open(final_video_path, 'rb') as f:
                        video_data = f.read()
                    st.download_button(
                        label="ä¸‹è½½æ‹¼æ¥è§†é¢‘",
                        data=video_data,
                        file_name="æ‹¼æ¥è§†é¢‘.mp4",
                        mime="video/mp4"
                    )
                else:
                    st.error("è§†é¢‘æ‹¼æ¥å¤±è´¥")

if __name__ == "__main__":
    main()

