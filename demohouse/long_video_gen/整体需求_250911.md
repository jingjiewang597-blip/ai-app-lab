使用方舟大模型实现一个Web应用

# 步骤一，分镜生成
1，用户输入一个场景需求，点击“分镜生成”按钮，保存场景需求到文件中，文件名为“用户输入场景.md”，并默认读取文件内容
2，调用豆包Seed1.6模型，使用“分镜生成Prompt”来生成分镜信息，注意，Prompt中{USER_INPUT}需要替换为用户输入的场景需求。把模型的输出内容显示在“分镜生成结果”中，并保存在文件中，文件名为“分镜生成结果.md”，下次展示首先从文件中读取内容

# 步骤二，分镜信息提取
1，当“分镜生成结果”不为空时，用户点击“提取分镜信息”按钮
2，调用豆包Seed1.6模型，使用“分镜信息提取Prompt”来分别提取分镜信息的场景和旁白，注意：Prompt中“{{input}}”需要替换为豆包Seed1.6模型生成的“分镜生成结果”内容，结果保存在文件中，文件名为“分镜信息提取结果.json”，并解析json内容，“画风”内容展示在“画风”，“角色设定”内容展示在“角色设定”，场景列表信息使用列表按行展示“场景”、“旁白”等内容，列表的列分别为：
1，序号
2，场景
3，旁白
4，生成分镜图片按钮
5，分镜图片
6，分镜生成视频的Prompt
7，生成分镜视频
8，分镜视频

# 步骤三，每一个场景生成图片
1， 当“分镜信息提取结果”不为空时，用户点击“生成分镜图片”按钮
2， 调用seedream模型，使用“分镜图片生成Prompt”，替换{场景}为该行“场景”内容，生成该场景的图片，并显示在列表中“分镜图片”列中，并保存到文件中，文件名为“分镜图片_序号.jpg”，下次展示从文件中读取

# 步骤四，每一个场景生成“生成视频”Prompt
1， 当“分镜信息提取结果”不为空时，用户点击“生成视频Prompt”按钮
2， 调用豆包Seed1.6模型，使用“分镜生成视频Prompt的Prompt”作为System Prompt，使用该行“场景”内容作为User Prompt，生成该场景的“生成视频Prompt”，显示在列中“分镜生成视频的Prompt”，并保存在文件中，文件名为“生成视频Prompt_序号.md”，下次展示从文件中读取

# 步骤五，每一个场景生成音频
1， 当“分镜信息提取结果”中的“旁白”不为空时，用户点击“生成音频”按钮
2， 调用语音合成模型，使用“旁白”内容作为输入，生成该场景的音频，并显示在列表中“分镜音频”列中，并保存URL到文件中，文件名为“分镜音频_序号.txt”

# 步骤六，每一个场景生成视频
1， 当“分镜图片”不为空时，用户点击“生成分镜视频”按钮
2， 调用seedance模型，使用该行“分镜生成视频的Prompt”和“分镜图片”作为输入，生成该场景的视频，
3， 若生成的分镜视频与分镜音频的时长不一致，调整视频的播放速度，使其播放的时长与音频时长一致，最终在页面展示根据音频时长调整过的分镜视频
4， 最终的分镜视频显示在列表中“分镜视频”列中，并保存URL到文件中，文件名为“分镜视频_序号.txt”
5， 并下载视频到“分镜视频”目录下，文件名为“分镜视频_序号.mp4”

# 步骤七，每一个场景生成的视频和音频合成为一个有音频的视频
1，点击“音视频拼接”按钮，拼接音频和视频为一个音视频，并保存到“文件生成”目录下，文件名为“音视频_序号.mp4”，页面再次打开时，优先读取文件中的内容
2， 并显示在“音视频拼接结果”中

# 步骤八，把所有音视频拼接成一个视频
1，点击“拼接视频”按钮，拼接所有音视频为一个长视频，并保存到“文件生成”目录下，文件名为“拼接视频.mp4”，页面再次打开时，优先读取文件

注意：不要修改Prompt内容
注意：所有生成的文件均保存在“文件生成”目录下